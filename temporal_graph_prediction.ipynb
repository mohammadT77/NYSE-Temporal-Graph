{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q kagglehub numpy pandas networkx matplotlib torch torch-geometric==2.4.0 torch-geometric-temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch-geometric==2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/NYSE-Temporal-Graph-Construction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd NYSE-Temporal-Graph-Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from os.path import join as join_path\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from torch_geometric_temporal import DynamicGraphTemporalSignal, Data\n",
    "from functools import cache\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_GRAPH_DIR = \"graph_data/train/infotech_thresh1\"\n",
    "TARGET_SECTORS = ['Information Technology']\n",
    "FILTER_BY_WEIGHT_THRESH = 5\n",
    "TRAINING_EPOCHS = 50\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1\n",
    "EMBED_DIM = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"dgawlik/nyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_df = pd.read_csv(join_path(dataset_path,\"fundamentals.csv\"))\n",
    "prices_split_adjusted_df = pd.read_csv(join_path(dataset_path, \"prices-split-adjusted.csv\"))\n",
    "prices_df = pd.read_csv(join_path(dataset_path, \"prices.csv\"))\n",
    "securities_df = pd.read_csv(join_path(dataset_path, \"securities.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of all symbols: 501\n",
      "Num of target symbols: 68\n"
     ]
    }
   ],
   "source": [
    "all_symbols = prices_split_adjusted_df['symbol'].sort_values().unique()\n",
    "\n",
    "def get_symbol_by_sector(sector):\n",
    "    return securities_df[securities_df['GICS Sector'] == sector]['Ticker symbol'].to_list()\n",
    "\n",
    "target_symbols = prices_split_adjusted_df['symbol'].sort_values().unique()\n",
    "\n",
    "target_symbols = []\n",
    "for sector in TARGET_SECTORS:\n",
    "    target_symbols += get_symbol_by_sector(sector)\n",
    "\n",
    "target_symbols.sort()\n",
    "    \n",
    "@cache\n",
    "def symbol_to_int(symbol: str):\n",
    "    if symbol not in target_symbols:\n",
    "        return -1\n",
    "    return target_symbols.index(symbol)\n",
    "\n",
    "@cache\n",
    "def int_to_symbol(idx):\n",
    "    idx = int(idx)\n",
    "    return target_symbols[idx]\n",
    "\n",
    "\n",
    "print(\"Num of all symbols:\", len(all_symbols))\n",
    "print(\"Num of target symbols:\", len(target_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2010, 1, 4) datetime.date(2010, 1, 5)\n",
      " datetime.date(2010, 1, 6) ... datetime.date(2016, 12, 28)\n",
      " datetime.date(2016, 12, 29) datetime.date(2016, 12, 30)]\n"
     ]
    }
   ],
   "source": [
    "prices_split_adjusted_df['date'] = pd.to_datetime(prices_split_adjusted_df['date']).dt.date\n",
    "dates = prices_split_adjusted_df['date'].sort_values().unique()\n",
    "\n",
    "@cache\n",
    "def any_to_date(date):\n",
    "    if not isinstance(date, pd._libs.tslibs.timestamps.Timestamp):\n",
    "        date = pd.to_datetime(date).date()\n",
    "    return date\n",
    "\n",
    "@cache\n",
    "def date_to_int(date):\n",
    "    date = any_to_date(date)\n",
    "    return dates.tolist().index(date)\n",
    "\n",
    "@cache\n",
    "def int_to_date(idx):\n",
    "    return dates[idx]\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_features_df = prices_split_adjusted_df.copy()\n",
    "node_features_df = node_features_df[node_features_df['symbol'].isin(target_symbols)]\n",
    "node_features_df['day_diff'] = ((node_features_df['close']) - (o:=node_features_df['open'])) / o * 100\n",
    "node_features_df['date'] = node_features_df['date'].apply(lambda x: date_to_int(x))\n",
    "node_features_df['symbol'] = node_features_df['symbol'].apply(lambda x: symbol_to_int(x))\n",
    "\n",
    "# Drop rows with symbol -1:\n",
    "node_features_df = node_features_df[node_features_df['symbol'] != -1]\n",
    "\n",
    "# rename symbol to node_id\n",
    "node_features_df = node_features_df.rename(columns={'symbol': 'node', 'date': 'time'})\n",
    "\n",
    "lower_bound = node_features_df['day_diff'].quantile(0.01)  # 1st percentile\n",
    "upper_bound = node_features_df['day_diff'].quantile(0.99)  # 99th percentile\n",
    "\n",
    "node_features_df['day_diff'] = node_features_df['day_diff'].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "\n",
    "\n",
    "node_features_df.sort_values(['time', 'node'], inplace=True)\n",
    "# node_features_df.head(10)\n",
    "node_features_df['day_diff'].describe()\n",
    "node_features_df['day_diff'].plot.hist(bins=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_date = lambda filename: filename.split(\"_\")[1].removesuffix(\".edgelist\")\n",
    "get_nx_graph = lambda fileName: nx.read_weighted_edgelist(join_path(TARGET_GRAPH_DIR, fileName))\n",
    "\n",
    "nx_graph_snapshots = [(get_date(fileName), get_nx_graph(fileName)) for fileName in os.listdir(TARGET_GRAPH_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of graphs: 1233\n",
      "Total num of edges: 2438163\n"
     ]
    }
   ],
   "source": [
    "print(\"Total num of graphs:\", len(nx_graph_snapshots))\n",
    "print(\"Total num of edges:\", sum([graph.number_of_edges() for _, graph in nx_graph_snapshots]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_graphs = []\n",
    "for date, nx_graph in nx_graph_snapshots:\n",
    "    time = date_to_int(date)\n",
    "    \n",
    "    today_node_features_df = node_features_df[node_features_df['time'] == time].set_index('node', inplace=False)\n",
    "\n",
    "    tomorrow_node_features_df = node_features_df[node_features_df['time'] == time + 1].set_index('node', inplace=False)\n",
    "\n",
    "    today_node_features_df = today_node_features_df.reindex(range(len(target_symbols)), fill_value=0.0)\n",
    "    tomorrow_node_features_df = tomorrow_node_features_df.reindex(range(len(target_symbols)), fill_value=0.0)\n",
    "    \n",
    "    today_node_features_df = today_node_features_df.drop(columns=['time'])\n",
    "\n",
    "    y = tomorrow_node_features_df['day_diff'].values\n",
    "    y = torch.tensor(y, device=device, dtype=torch.float)\n",
    "\n",
    "    # convert to torch\n",
    "    edges_data = pd.DataFrame.from_dict(nx_graph.edges.data())\n",
    "\n",
    "    edges_data[0] = edges_data[0].apply(symbol_to_int)\n",
    "    edges_data[1] = edges_data[1].apply(symbol_to_int)\n",
    "    edges_data[2] = edges_data[2].apply(lambda x: x['weight'])\n",
    "\n",
    "    # Filter by weight\n",
    "    edges_data = edges_data[edges_data[2] > FILTER_BY_WEIGHT_THRESH]\n",
    "\n",
    "    x = torch.tensor(today_node_features_df.values, dtype=torch.float32, device=device)\n",
    "    \n",
    "    edge_index = edges_data.loc[:,0:1].values\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long, device=device).t().contiguous()\n",
    "\n",
    "    edge_weight = edges_data.loc[:,2].values\n",
    "    edge_weight = torch.tensor(edge_weight, dtype=torch.float, device=device)\n",
    "\n",
    "    torch_graph = Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)\n",
    "    torch_graphs.append(torch_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1025,  0.5463,  1.7819, -0.1579, -0.1172,  0.3191, -1.3271,  2.8516,\n",
      "        -0.3511, -1.9403,  0.7117,  0.2638,  1.0587,  0.0672, -0.0813,  0.0000,\n",
      "         1.0893,  0.2104,  1.9115, -0.5885,  0.0000, -1.4264,  3.5431,  0.7919,\n",
      "         0.0918,  1.4546, -1.1083, -0.5086, -0.5086,  0.1143,  0.0000,  1.0165,\n",
      "        -0.7239, -0.6303, -0.3343,  0.1625, -1.5096, -0.9227, -0.1612, -0.4524,\n",
      "        -0.6826, -1.7112,  0.3566, -1.1321,  2.8545, -3.8454, -1.4956,  1.8458,\n",
      "         0.4045, -0.1621,  0.0000,  1.1574,  0.0000, -0.6416, -1.8028,  1.0745,\n",
      "        -0.5435,  0.3237, -1.2019,  0.1163, -0.3468, -0.1947,  0.8471,  2.4476,\n",
      "        -0.7311, -1.0659,  0.1159,  0.0581], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch_graphs[0].y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs len: 1233\n"
     ]
    }
   ],
   "source": [
    "print(\"Graphs len:\", len(torch_graphs))\n",
    "# print(\"Node features len:\", len(torch_node_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = DynamicGraphTemporalSignal(\n",
    "#     [tg.edge_index for tg in torch_graphs],\n",
    "#     [tg.edge_attr for tg in torch_graphs],\n",
    "#     [tg.x for tg in torch_graphs],\n",
    "#     [tg.y for tg in torch_graphs],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataBatch(x=[2176, 6], edge_index=[2, 23037], edge_attr=[23037], y=[2176], batch=[2176], ptr=[33]),\n",
       " DataBatch(x=[2176, 6], edge_index=[2, 23247], edge_attr=[23247], y=[2176], batch=[2176], ptr=[33])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class NYSEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, graphs, window_size=2):\n",
    "        self.graphs = graphs\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise StopIteration\n",
    "        if idx < 0:\n",
    "            idx = len(self) + idx\n",
    "        return self.graphs[idx:idx + self.window_size]  # 3 snapshots\n",
    "\n",
    "\n",
    "dataset = NYSEDataset(torch_graphs)\n",
    "loader = DataLoader(dataset, batch_size=32,shuffle=True)\n",
    "\n",
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch:\n",
      " Predictor(\n",
      "  (recurrent): GConvGRU(\n",
      "    (conv_x_z): ChebConv(6, 32, K=10, normalization=sym)\n",
      "    (conv_h_z): ChebConv(32, 32, K=10, normalization=sym)\n",
      "    (conv_x_r): ChebConv(6, 32, K=10, normalization=sym)\n",
      "    (conv_h_r): ChebConv(32, 32, K=10, normalization=sym)\n",
      "    (conv_x_h): ChebConv(6, 32, K=10, normalization=sym)\n",
      "    (conv_h_h): ChebConv(32, 32, K=10, normalization=sym)\n",
      "  )\n",
      "  (decoder): GraphDecoder(\n",
      "    (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Num params: 40897\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.nn.recurrent import GConvGRU, GCLSTM\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCN, GCNConv\n",
    "\n",
    "\n",
    "class GraphEmbedder(GCN):\n",
    "    \"\"\"Embedder to extract node embeddings from a graph snapshot.\"\"\"\n",
    "    def __init__(self, input_dim, embed_dim):\n",
    "        super(GraphEmbedder, self).__init__(input_dim, embed_dim, 1, embed_dim)\n",
    "        # super(GraphEmbedder, self).__init__()\n",
    "        # self.gcn1 = GCN(input_dim, embed_dim,)\n",
    "        # # self.gcn2 = GCNConv(embed_dim, embed_dim)\n",
    "\n",
    "    # def forward(self, x, edge_index, edge_weight=None):\n",
    "    #     print(x.shape, edge_index.shape, edge_weight.shape)\n",
    "    #     x = self.gcn1(x, edge_index, edge_weight)\n",
    "    #     # x = torch.relu(x)\n",
    "    #     # x = self.gcn2(x, edge_index, edge_weight)\n",
    "    #     return x  # Returns node embeddings\n",
    "\n",
    "class GraphRecEncoder(nn.Module):\n",
    "    \"\"\"Recurrent module to update node embeddings.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphRecEncoder, self).__init__()\n",
    "        self.gru = nn.GRUCell(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, embeddings, hidden_state=None):\n",
    "        if hidden_state is None:\n",
    "            hidden_state = torch.zeros_like(embeddings)\n",
    "        new_state = self.gru(embeddings, hidden_state)\n",
    "        return new_state  # Updated embeddings (new hidden state)\n",
    "\n",
    "class GraphDecoder(nn.Module):\n",
    "    \"\"\"Decoder to predict values based on final node embeddings.\"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super(GraphDecoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.fc2 = nn.Linear(embed_dim*2, embed_dim)\n",
    "        self.fc3 = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        x = torch.relu(self.fc1(embeddings))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x  # Prediction for each node\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, embed_dim=EMBED_DIM, input_dim=6):\n",
    "        super(Predictor, self).__init__()\n",
    "        # self.embedder = GCN(input_dim, embed_dim, 1, embed_dim)\n",
    "        # self.encoder = GraphRecEncoder(embed_dim, embed_dim)\n",
    "        self.recurrent = GConvGRU(input_dim, embed_dim, 10)\n",
    "        self.decoder = GraphDecoder(embed_dim)\n",
    "\n",
    "    def forward(self, snapshots):\n",
    "        prev_emb = None\n",
    "        for graph in snapshots:\n",
    "            # emb = self.embedder(graph.x, graph.edge_index, graph.edge_attr)\n",
    "            # emb = self.encoder(emb, prev_emb) # Recurrent\n",
    "            # prev_emb = emb\n",
    "            prev_emb = self.recurrent(graph.x, graph.edge_index, graph.edge_attr, prev_emb)\n",
    "            \n",
    "        return self.decoder(prev_emb)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Arch:\\n\",_m:=Predictor())\n",
    "print(\"Num params:\", sum(p.numel() for p in _m.parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█▏        | 140/1231 [00:57<07:25,  2.45it/s, loss=1.93, total_loss=258]\n",
      "\n",
      "\u001b[A                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████▉| 1230/1231 [01:19<00:00, 15.52it/s, loss=3.97, total_loss=2.51e+3]\n",
      "Epoch 2: 100%|█████████▉| 1230/1231 [01:17<00:00, 15.90it/s, loss=3.97, total_loss=2.51e+3] \n",
      "Epoch 3: 100%|█████████▉| 1230/1231 [01:16<00:00, 16.17it/s, loss=3.97, total_loss=2.5e+3]  \n",
      "Epoch 4: 100%|█████████▉| 1230/1231 [01:13<00:00, 16.71it/s, loss=3.98, total_loss=2.5e+3]  \n",
      "Epoch 5: 100%|█████████▉| 1230/1231 [01:14<00:00, 16.47it/s, loss=3.98, total_loss=2.5e+3]  \n",
      "Epoch 6: 100%|█████████▉| 1230/1231 [01:13<00:00, 16.80it/s, loss=3.98, total_loss=2.5e+3]  \n",
      "Epoch 7: 100%|█████████▉| 1230/1231 [01:14<00:00, 16.47it/s, loss=3.98, total_loss=2.5e+3]  \n",
      "Epoch 8: 100%|█████████▉| 1230/1231 [01:14<00:00, 16.49it/s, loss=3.98, total_loss=2.5e+3]  \n",
      "Epoch 9: 100%|█████████▉| 1230/1231 [01:17<00:00, 16.67it/s, loss=0.8, total_loss=2.5e+3]   "
     ]
    }
   ],
   "source": [
    "model = Predictor().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "TRAINING_EPOCHS = 1000\n",
    "for epoch in range(TRAINING_EPOCHS):\n",
    "    total_loss = 0\n",
    "    model.train(True)\n",
    "    pbar = tqdm(dataset, desc=\"Epoch {}\".format(epoch + 1))\n",
    "    pbar.clear()\n",
    "    for i,snapshots in enumerate(dataset):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(snapshots)\n",
    "        true_y = snapshots[-1].y\n",
    "        loss = criterion(pred.squeeze(), true_y)\n",
    "    \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is None:\n",
    "                print(f\"No gradient for {name}\")\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pbar.set_postfix(loss=loss.item(), total_loss=total_loss)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            pbar.update(10)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"weights/temporal_link_prediction_e{epoch+1}_model.pt\")\n",
    "\n",
    "torch.save(model.state_dict(), \"weights/temporal_link_prediction_last_model.pt\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60])\n",
      "tensor([-0.0748,  0.0994,  0.1127,  0.0637,  0.1005,  0.0991,  0.0963,  0.0241,\n",
      "         0.0261,  0.0941, -0.0601,  0.0280,  0.0003, -0.0086,  0.0227,  0.0011,\n",
      "         0.0420, -0.0430,  0.0222,  0.1496,  0.0222,  0.0320,  0.1129,  0.0516,\n",
      "         0.0222,  0.0558,  0.0874, -0.0101,  0.1060,  0.0245,  0.0011,  0.0500,\n",
      "         0.0742,  0.0662, -0.0256,  0.0994,  0.0442,  0.0046,  0.0654,  0.0678,\n",
      "         0.0226,  0.0847, -0.0103,  0.0419,  0.0402,  0.0163,  0.0024,  0.0222,\n",
      "         0.0192, -0.0010,  0.0011, -0.0103,  0.0011, -0.0152,  0.0214,  0.0461,\n",
      "         0.0416, -0.0152,  0.0431,  0.0522,  0.0298,  0.0096,  0.0861,  0.1085,\n",
      "         0.0566,  0.0823, -0.0420,  0.0074], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "tensor([-0.4906, -0.6731, -1.5615,  0.1577,  0.2718, -2.3323, -0.6586, -1.1814,\n",
      "         0.6359,  0.1990,  4.1646, -1.3875, -0.0678, -2.4753,  0.6602,  0.0000,\n",
      "         0.1704,  1.6396,  4.2580, -0.4919, -2.3481, -2.0386, -0.4448,  0.2926,\n",
      "        -1.9756, -4.1989,  0.8696, -1.1303, -1.0033,  1.0008,  0.0000, -0.0618,\n",
      "         1.2989, -0.0211,  0.4189, -0.2416,  0.3253,  0.9793,  0.2252,  0.3884,\n",
      "        -0.0812,  0.8604,  0.5099,  1.3281, -1.0116, -1.7140, -1.9494,  0.1096,\n",
      "        -0.2187, -0.8821,  0.0000, -0.4892,  0.0000, -0.1434, -0.8725, -1.1082,\n",
      "         0.5470, -0.9908,  0.3606, -0.5832,  0.5515,  0.8164, -0.2308, -0.7620,\n",
      "         0.4321,  0.9399,  0.5952, -4.1989], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█▏        | 140/1231 [00:29<01:16, 14.31it/s, loss=1.93, total_loss=258]"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = Predictor().to(device)\n",
    "model.load_state_dict(torch.load(\"temporal_link_prediction_e10_model.pt\"))\n",
    "\n",
    "dict(model.named_parameters())\n",
    "d = dataset[100]\n",
    "print(model(d).unique().shape)\n",
    "print(model(d).squeeze())\n",
    "print(d[-1].y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric_temporal.nn.recurrent import GCLSTM\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, node_features, num_classes):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent_1 = GCLSTM(node_features, 32, 5)\n",
    "        self.recurrent_2 = GCLSTM(32, 16, 5)\n",
    "        self.linear = torch.nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.recurrent_2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
