{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'NYSE-Temporal-Graph-Construction'\n",
      "/teamspace/studios/this_studio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd NYSE-Temporal-Graph-Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from os.path import join as join_path\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import cache\n",
    "import torch\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU, GCLSTM\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SECTORS = ['Information Technology']\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"dgawlik/nyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_df = pd.read_csv(join_path(dataset_path,\"fundamentals.csv\"))\n",
    "df = pd.read_csv(join_path(dataset_path, \"prices.csv\"))\n",
    "prices_split_adjusted_df = pd.read_csv(join_path(dataset_path, \"prices-split-adjusted.csv\"))\n",
    "securities_df = pd.read_csv(join_path(dataset_path, \"securities.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of all symbols: 501\n",
      "Num of target symbols: 68 ['AAPL', 'ACN', 'ADBE', 'ADI', 'ADP', 'ADS', 'ADSK', 'AKAM', 'AMAT', 'APH', 'ATVI', 'AVGO', 'CA', 'CRM', 'CSCO', 'CSRA', 'CTSH', 'CTXS', 'EA', 'EBAY', 'FB', 'FFIV', 'FIS', 'FISV', 'FLIR', 'FSLR', 'GLW', 'GOOG', 'GOOGL', 'GPN', 'HPE', 'HPQ', 'HRS', 'IBM', 'INTC', 'INTU', 'JNPR', 'KLAC', 'LLTC', 'LRCX', 'MA', 'MCHP', 'MSFT', 'MSI', 'MU', 'NFLX', 'NTAP', 'NVDA', 'ORCL', 'PAYX', 'PYPL', 'QCOM', 'QRVO', 'RHT', 'STX', 'SWKS', 'SYMC', 'TDC', 'TEL', 'TSS', 'TXN', 'V', 'VRSN', 'WDC', 'WU', 'XLNX', 'XRX', 'YHOO']\n"
     ]
    }
   ],
   "source": [
    "all_symbols = prices_split_adjusted_df['symbol'].sort_values().unique()\n",
    "\n",
    "def get_symbol_by_sector(sector):\n",
    "    return securities_df[securities_df['GICS Sector'] == sector]['Ticker symbol'].to_list()\n",
    "\n",
    "target_symbols = prices_split_adjusted_df['symbol'].sort_values().unique()\n",
    "\n",
    "target_symbols = []\n",
    "\n",
    "if not TARGET_SECTORS or len(TARGET_SECTORS) == 0:\n",
    "    target_symbols = all_symbols.tolist()\n",
    "else:\n",
    "    for sector in TARGET_SECTORS:\n",
    "        target_symbols += get_symbol_by_sector(sector)\n",
    "\n",
    "target_symbols.sort()\n",
    "    \n",
    "@cache\n",
    "def symbol_to_int(symbol: str):\n",
    "    if symbol not in target_symbols:\n",
    "        return -1\n",
    "    return target_symbols.index(symbol)\n",
    "\n",
    "@cache\n",
    "def int_to_symbol(idx):\n",
    "    idx = int(idx)\n",
    "    return target_symbols[idx]\n",
    "\n",
    "\n",
    "print(\"Num of all symbols:\", len(all_symbols))\n",
    "print(\"Num of target symbols:\", len(target_symbols), target_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2010, 1, 4) datetime.date(2010, 1, 5)\n",
      " datetime.date(2010, 1, 6) ... datetime.date(2016, 12, 28)\n",
      " datetime.date(2016, 12, 29) datetime.date(2016, 12, 30)]\n"
     ]
    }
   ],
   "source": [
    "prices_split_adjusted_df['date'] = pd.to_datetime(prices_split_adjusted_df['date']).dt.date\n",
    "dates = prices_split_adjusted_df['date'].sort_values().unique()\n",
    "\n",
    "\n",
    "def any_to_date(date):\n",
    "    if not isinstance(date, pd._libs.tslibs.timestamps.Timestamp):\n",
    "        date = pd.to_datetime(date).date()\n",
    "    return date\n",
    "\n",
    "@cache\n",
    "def date_to_int(date):\n",
    "    date = any_to_date(date)\n",
    "    return dates.tolist().index(date)\n",
    "\n",
    "@cache\n",
    "def int_to_date(idx):\n",
    "    return dates[idx]\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_df, fill_missing=True, repeat=1):\n",
    "\n",
    "    df = target_df.copy()\n",
    "    \n",
    "    df['date'] = df['date'].apply(date_to_int)\n",
    "    df['symbol'] = df['symbol'].apply(symbol_to_int)\n",
    "\n",
    "    # remove symbol == -1\n",
    "    df = df[df['symbol'] != -1]\n",
    "\n",
    "    df.sort_values(['date', 'symbol'], inplace=True)\n",
    "\n",
    "\n",
    "    for date, group in df.groupby('date'):\n",
    "        group.drop('date', axis=1, inplace=True)\n",
    "        group.set_index('symbol', inplace=True)\n",
    "        if fill_missing:\n",
    "            group = group.reindex(range(len(target_symbols)), fill_value=0.0)\n",
    "            \n",
    "        if repeat > 1:\n",
    "            for _ in range(repeat):\n",
    "                yield date, group\n",
    "        else:\n",
    "            yield date, group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (68, 5)\n",
      "1 (68, 5)\n"
     ]
    }
   ],
   "source": [
    "for date, batch in load_data(prices_split_adjusted_df.sort_values('date').head(500)):\n",
    "    print(date, batch.to_numpy().shape)\n",
    "    \n",
    "\n",
    "batched_data = dict(load_data(prices_split_adjusted_df.sort_values('date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params: 1015026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphConstructor(\n",
       "  (q): Linear(in_features=5, out_features=501, bias=True)\n",
       "  (k): Linear(in_features=5, out_features=501, bias=True)\n",
       "  (v): Linear(in_features=5, out_features=501, bias=True)\n",
       "  (att): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=501, out_features=501, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GraphConstructor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_nodes=len(target_symbols), temp=1.0):\n",
    "        super(GraphConstructor, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.temp = temp\n",
    "\n",
    "        self.q = torch.nn.Linear(input_dim, num_nodes)\n",
    "        self.k = torch.nn.Linear(input_dim, num_nodes)\n",
    "        self.v = torch.nn.Linear(input_dim, num_nodes)\n",
    "\n",
    "        self.att = torch.nn.MultiheadAttention(num_nodes, num_heads=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.q(x)\n",
    "        K = self.k(x)\n",
    "        V = self.v(x)\n",
    "\n",
    "        output, attention_weights = self.att(Q,K,V)\n",
    "        adj = output\n",
    "        adj = torch.nn.functional.sigmoid(output/self.temp)\n",
    "        # set diameter to 0\n",
    "        adj = adj.masked_fill(torch.eye(adj.shape[0], dtype=torch.bool), 0)\n",
    "        return adj\n",
    "\n",
    "\n",
    "# constructor = Attention(input_dim=5, head_dim=2, normalize=False, verbose=False).to(device)\n",
    "constructor = GraphConstructor(input_dim=5, num_nodes=len(all_symbols)).to(device)\n",
    "# Num of params:\n",
    "print(\"Num params:\", sum(p.numel() for p in constructor.parameters()))\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "d = torch.tensor(batched_data[0].to_numpy(), dtype=torch.float).to(device)\n",
    "adj_matrix = constructor(d)\n",
    "print(adj_matrix.shape, adj_matrix)\n",
    "\n",
    "\n",
    "model  = constructor\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0192, 0.2229, 0.1259, 0.3523],\n",
      "        [0.1935, 0.0000, 0.0669, 0.4388, 0.0223],\n",
      "        [0.5593, 0.4562, 0.0000, 0.4178, 0.5414],\n",
      "        [0.4217, 0.4275, 0.1659, 0.0000, 0.6158],\n",
      "        [0.9529, 0.0117, 0.3945, 0.2837, 0.0000]])\n",
      "tensor([[0., 1., 1., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def random_adj_matrix(size):\n",
    "    a = torch.rand(size, size, device=device)\n",
    "    # Set diamter to zero\n",
    "    for i in range(size):\n",
    "        a[i, i] = 0\n",
    "    \n",
    "    return a\n",
    "\n",
    "def random_unweighted(size):\n",
    "    a = random_adj_matrix(size)\n",
    "    # Set weights to 1 if greeated than 0.5\n",
    "    a[a >= 0.5] = 1\n",
    "    a[a < 0.5] = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def fully_connected(size):\n",
    "    a = torch.ones(size, size, device=device)\n",
    "    for i in range(size):\n",
    "        a[i, i] = 0\n",
    "    return a\n",
    "\n",
    "print(random_adj_matrix(5))\n",
    "print(random_unweighted(5))\n",
    "print(fully_connected(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_graph = random_unweighted(len(target_symbols))\n",
    "\n",
    "def train(model, epochs=100, true_graph=true_graph):\n",
    "    print(\"True graph\", true_graph[0][0:10])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train(True)\n",
    "        pbar = tqdm(range(len(dates)), desc=\"Epoch {}\".format(epoch + 1))\n",
    "        pbar.clear()\n",
    "        for i, (date, date_data) in enumerate(load_data(prices_split_adjusted_df.sort_values('date'), repeat=24)):\n",
    "            optimizer.zero_grad()\n",
    "            date_data = torch.tensor(date_data.to_numpy(), dtype=torch.float).to(device)\n",
    "            pred = model(date_data)\n",
    "\n",
    "            loss = criterion(pred, true_graph)\n",
    "            \n",
    "            # if i % (24*100) == 0:\n",
    "            print(i, \"pred\", pred[0][0:10], \"loss\", loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "train(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
