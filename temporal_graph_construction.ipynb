{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kagglehub numpy pandas networkx matplotlib\n",
    "# !python -m pip install -q pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'NYSE-Temporal-Graph-Construction'\n",
      "/teamspace/studios/this_studio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd NYSE-Temporal-Graph-Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import kagglehub.datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from os.path import join as join_path\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 2\n",
    "TARGET_SECTORS = ['Real Estate', 'Information Technology', 'Materials', 'Telecommunications Services']\n",
    "DIR_NAME = 'rimt_thresh2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"dgawlik/nyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_pd = pd.read_csv(join_path(dataset_path,\"fundamentals.csv\"))\n",
    "prices_pd = pd.read_csv(join_path(dataset_path, \"prices.csv\"))\n",
    "prices_split_adjusted_pd = pd.read_csv(join_path(dataset_path, \"prices-split-adjusted.csv\"))\n",
    "securities_pd = pd.read_csv(join_path(dataset_path, \"securities.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(securities_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GICS Sector\n",
       "Consumer Discretionary         85\n",
       "Consumer Staples               37\n",
       "Energy                         36\n",
       "Financials                     64\n",
       "Health Care                    59\n",
       "Industrials                    69\n",
       "Information Technology         68\n",
       "Materials                      25\n",
       "Real Estate                    29\n",
       "Telecommunications Services     5\n",
       "Utilities                      28\n",
       "Name: Ticker symbol, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols = prices_pd['symbol'].unique()\n",
    "\n",
    "def get_symbol_by_sector(sector):\n",
    "    return securities_pd[securities_pd['GICS Sector'] == sector]['Ticker symbol'].to_list()\n",
    "\n",
    "securities_pd.groupby('GICS Sector')['Ticker symbol'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2010, 1, 4) datetime.date(2010, 1, 5)\n",
      " datetime.date(2010, 1, 6) ... datetime.date(2016, 12, 28)\n",
      " datetime.date(2016, 12, 29) datetime.date(2016, 12, 30)]\n",
      "2010-01-04\n",
      "1761\n"
     ]
    }
   ],
   "source": [
    "prices_pd['date'] = pd.to_datetime(prices_pd['date'], format='mixed').dt.date\n",
    "dates = prices_pd['date'].sort_values().unique()\n",
    "\n",
    "\n",
    "def any_to_date(date):\n",
    "    if not isinstance(date, pd._libs.tslibs.timestamps.Timestamp):\n",
    "        date = pd.to_datetime(date, format='mixed').date()\n",
    "    return date\n",
    "\n",
    "\n",
    "def date_to_int(date):\n",
    "    date = any_to_date(date)\n",
    "    return dates.tolist().index(date)\n",
    "\n",
    "def int_to_date(idx):\n",
    "    return dates[idx]\n",
    "\n",
    "print(dates)\n",
    "print(int_to_date(0))\n",
    "print(date_to_int(int_to_date(len(dates)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(target_prices_df = prices_pd):\n",
    "    target_prices_df['day_diff'] = ((target_prices_df['close']) - (o:=target_prices_df['open'])) / o\n",
    "    # target_prices_df['close_1d'] = target_prices_df['close'].pct_change(1)\n",
    "    # target_prices_df['close_3d'] = target_prices_df['close'].pct_change(3)\n",
    "\n",
    "\n",
    "def similarity_score(record1: pd.Series, record2: pd.Series) -> float:\n",
    "    norm_factor = 1e-5\n",
    "    \n",
    "    if record1['symbol'] == record2['symbol']:\n",
    "        return 0\n",
    "    \n",
    "    abs_diff = abs((record2['day_diff'])-(record1['day_diff'])) + norm_factor\n",
    "    sim = -np.log(abs_diff)\n",
    "    if sim > SIMILARITY_THRESHOLD:\n",
    "        return np.round(sim, 3)\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def build_temporal_graphs(target_prices_df: pd.DataFrame, similarity_score = similarity_score):\n",
    "    add_features(target_prices_df)\n",
    "    target_prices_df.fillna(0, inplace=True)\n",
    "    target_prices_df.sort_values(by=['date'], inplace=True)\n",
    "\n",
    "    for date, group in target_prices_df.groupby('date'):\n",
    "        group.reset_index(inplace=True)\n",
    "        graph = nx.Graph()\n",
    "        dateIdx = date_to_int(date)\n",
    "        for i, record1 in group.iterrows():\n",
    "            group['sim_score'] = group.apply(lambda record2: similarity_score(record1, record2), axis=1)\n",
    "\n",
    "            edges = group[group['sim_score'] > 0]\n",
    "            \n",
    "            for j, edge_row in edges.iterrows():\n",
    "                graph.add_edge(record1['symbol'], edge_row['symbol'], weight=edge_row['sim_score'], time=dateIdx)\n",
    "\n",
    "        yield dateIdx, date, graph\n",
    "\n",
    "\n",
    "def save_graph(prefix: str, dateIdx: int, date, graph: nx.Graph, base_dir='graph_data/train'):\n",
    "    dir = join_path(base_dir, prefix)\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    \n",
    "    file_name = f\"{dateIdx}_{date}.edgelist\"\n",
    "    file_path = join_path(dir, file_name)\n",
    "    nx.write_weighted_edgelist(graph, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1233 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38132/3176227639.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_prices_df['day_diff'] = ((target_prices_df['close']) - (o:=target_prices_df['open'])) / o\n",
      "/tmp/ipykernel_38132/3176227639.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_prices_df.fillna(0, inplace=True)\n",
      "/tmp/ipykernel_38132/3176227639.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_prices_df.sort_values(by=['date'], inplace=True)\n",
      "  1%|          | 12/1233 [00:10<18:43,  1.09it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m target_graphs \u001b[38;5;241m=\u001b[39m build_temporal_graphs(test_prices_df[test_prices_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(target_symbols)])\n\u001b[1;32m     10\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(train_end_date_idx))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dateIdx, date, graph \u001b[38;5;129;01min\u001b[39;00m target_graphs:\n\u001b[1;32m     12\u001b[0m     save_graph(DIR_NAME, dateIdx, date, graph)\n\u001b[1;32m     13\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 34\u001b[0m, in \u001b[0;36mbuild_temporal_graphs\u001b[0;34m(target_prices_df, similarity_score)\u001b[0m\n\u001b[1;32m     31\u001b[0m     edges \u001b[38;5;241m=\u001b[39m group[group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, edge_row \u001b[38;5;129;01min\u001b[39;00m edges\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 34\u001b[0m         graph\u001b[38;5;241m.\u001b[39madd_edge(\u001b[43mrecord1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msymbol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, edge_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m], weight\u001b[38;5;241m=\u001b[39medge_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim_score\u001b[39m\u001b[38;5;124m'\u001b[39m], time\u001b[38;5;241m=\u001b[39mdateIdx)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m dateIdx, date, graph\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pandas/core/series.py:1024\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1023\u001b[0m key_is_scalar \u001b[38;5;241m=\u001b[39m is_scalar(key)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1025\u001b[0m     key \u001b[38;5;241m=\u001b[39m unpack_1tuple(key)\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_symbols = []\n",
    "for sector in TARGET_SECTORS:\n",
    "    target_symbols += get_symbol_by_sector(sector)\n",
    "\n",
    "train_end_date_idx = int(len(dates)*0.7)\n",
    "test_prices_df = prices_pd[prices_pd['date'] >= int_to_date(0)][prices_pd['date'] < int_to_date(train_end_date_idx)]\n",
    "\n",
    "target_graphs = build_temporal_graphs(test_prices_df[test_prices_df['symbol'].isin(target_symbols)])\n",
    "\n",
    "pbar = tqdm(range(train_end_date_idx))\n",
    "for dateIdx, date, graph in target_graphs:\n",
    "    save_graph(DIR_NAME, dateIdx, date, graph)\n",
    "    pbar.update(1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
